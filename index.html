<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Kenneth Marino</title>

  <meta name="author" content="Kenneth Marino">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Kenneth Marino</name>
              <p>
                I am a PhD student at Carnegie Melon University's <a href="https://www.ml.cmu.edu/">Machine Learning Department</a> advised by <a href="http://www.cs.cmu.edu/~abhinavg/">Abhinav Gupta</a>. I am funded by the <a href="https://ndseg.asee.org/">NDSEG</a> and was previously funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>.
              </p>
              <p>
                I completed my undergraduate education at Georgia Tech with a major in Computer Engineering and a minor in Computer Science.
              </p>
              <p>
                I have been known to occasionally <a href="https://ai-insanity.com">blog</a> and <a href="https://twitter.com/Kenneth_Marino">tweet</a> things.
              </p>
              <p style="text-align:center">
                <a href="mailto:kdmarino@andrew.cmu.edu">Email</a> &nbsp/&nbsp
                <a href="data/Kenneth_Marino_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=6bQxCusAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/KMarino/">Github</a>&nbsp/&nbsp
                <a href="https://twitter.com/Kenneth_Marino"> Twitter </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/kenny.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/kenny.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Latest News</heading>
              <p>
                  We've released the OK-VQA dataset at <a hreft="https://okvqa.allenai.org/">https://okvqa.allenai.org/</a>. You can also browse through the data and keep track of SOTA results on our leaderboard.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                  My research interests include incorporating structured knowledge into end-to-end learning, CV+NLP, RL and general problems in deep learning.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/OKVQATeaser.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/1906.00067.pdf">
                <papertitle>OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge</papertitle>
              </a>
              <br>
                <strong>Kenneth Marino</strong>,
                <a href="https://allenai.org/team/mohammadr/">Mohammad Rastegari</a>
                <a href="https://homes.cs.washington.edu/~ali/"Ali Farhadi2</a>
                <a href="https://cs.stanford.edu/~roozbeh/">Roozbeh Mottaghi</a>
              <br>
              <em>CVPR</em> 2019
              <p>OK-VQA is a new dataset for visual question answering that requires methods which can draw upon outside knowledge to answer questions.</p>
              <p><a href="https://arxiv.org/pdf/1906.00067.pdf">[Paper]</a><a href="https://okvqa.allenai.org/">[Website]</a></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/EP3.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://openreview.net/pdf?id=SJz1x20cFQ">
                <papertitle>Hierarchical RL Using an Ensemble of Proprioceptive Periodic Policies</papertitle>
              </a>
              <br>
                <strong>Kenneth Marino</strong>,
                <a href="http://www.cs.cmu.edu/~abhinavg/">Abhinav Gupta</a>,
                <a href="https://cs.nyu.edu/~fergus/">Rob Fergus</a>,
                <a href="https://research.fb.com/people/szlam-arthur/">Arthur Szlam</a>
              <br>
              <em>ICLR</em> 2019
              <p>We introduce a simple, robust approach to hierarchically training an agent in the setting of sparse reward tasks taking inspiration from ideas of periodicity and proprioception.</p>
              <p><a href="https://openreview.net/pdf?id=SJz1x20cFQ">[Paper]</a><a href="https://sites.google.com/view/hrl-ep3">[Website]</a><a href="https://github.com/KMarino/hrl-ep3">[Code]</a></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/poseknowsteaser.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/1705.00053.pdf">
                <papertitle>The Pose Knows: Video Forecasting by Generating Pose Futures</papertitle>
              </a>
              <br>

                <a href="http://jacobcwalker.com/">Jacob Walker</a>,
                <strong>Kenneth Marino</strong>,
                <a href="http://www.cs.cmu.edu/~abhinavg/">Abhinav Gupta</a>,
                <a href="http://www.cs.cmu.edu/~./hebert/">Martial Hebert</a>
              <br>
              <em>ICCV</em> 2017
              <p>We introduce a new method for video forcasting that exploits human pose detectors as a free source of supervision to break the forecasting problem into a high-level pose prediction and then a low-level video stream prediciton.</p>
              <p><a href="https://arxiv.org/pdf/1705.00053.pdf">[Paper]</a><a href="http://jacobcwalker.com/POS/POS.html">[Website]</a><a href="https://github.com/puffin444/poseknows">[Code]</a></p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/TMYNTeaser.png" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/1612.04844.pdf">
                <papertitle>The More You Know: Using Knowledge Graphs for Image Classification</papertitle>
              </a>
              <br>
                <strong>Kenneth Marino</strong>,
                <a href="http://www.cs.cmu.edu/~abhinavg/">Abhinav Gupta</a>,
                <a href="https://cs.nyu.edu/~fergus/">Rob Fergus</a>,
                <a href="https://research.fb.com/people/szlam-arthur/">Arthur Szlam</a>
              <br>
              <em>CVPR</em> 2017
              <p>We introduce the Graph Search Neural Network as a way of efficiently incorporating large knowledge graphs into an end-to-end vision classification pipeline.</p>
              <p><a href="https://arxiv.org/pdf/1612.04844.pdf">[Paper]</a><a href="https://github.com/KMarino/GSNN_TMYN">[Code]</a></p>
            </td>
          </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service & Teaching</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cmulogosquare.jpeg" width="160" height="160"></td>
            <td width="75%" valign="center">
              MLD Ph.D Admissions Committee (2019-2020)
              <br>
              <br>
              MLD M.S. Admissions Committee (2016-2017)
              <br>
              <br>
              CMU Graduate Student Assembly (2017-Present)
              <br>
              <br>
              Refereed for CVPR, ICCV, and ECCV
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cmupretty.jpeg" alt="cmu" width="160" height="160">
            </td>
            <td width="75%" valign="center">
              <a href="https://sites.google.com/andrew.cmu.edu/16824-spring2019/">Graduate Student Instructor, 16-824 Visual Learning and Recognition, Spring 2019</a>
              <br>
              <br>
              <a href="http://www.cs.cmu.edu/~ninamf/courses/401sp18/">Graduate Student Instructor, 10-401 Introduction to Machine Learning, Spring 2018</a>
            </td>
        </tr>
      </td>
    </tr>
  </table>
</body>

</html>
